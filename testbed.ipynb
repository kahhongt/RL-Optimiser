{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a16819-6252-4591-a161-77f5e63a2c25",
   "metadata": {},
   "source": [
    "### Testbed for Optimising Asset Returns using Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f502f5-8fae-4c94-85e3-70270a36db74",
   "metadata": {},
   "source": [
    "- Using Proximal Policy Optimising\n",
    "- Define Observation Space\n",
    "- Define Action Space\n",
    "- Define Step Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2664ebf-eff9-49a4-9df4-054f80edc6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1d36f-0ab6-458f-8cdd-e99d9187a3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da9d690-91e7-47f4-a90e-09019ce852d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af87a9c-6678-4128-9439-21effdd6f6af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53496834-c4a9-4942-8607-d7e93ce9a7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e4e19-ed17-47ce-8072-d2ddd76f2612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayenv",
   "language": "python",
   "name": "bayenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
